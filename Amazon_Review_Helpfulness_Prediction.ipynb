{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from util import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filename = './reviews_Office_Products.json'\n",
    "meta_filename = './meta_Office_Products.json'\n",
    "filename_without_extension = os.path.splitext(os.path.basename(filename))[0]\n",
    "data = read_review_json_file(filename, meta_filename)\n",
    "populate_fields(data)\n",
    "np.random.seed(42)\n",
    "train_indexes, valid_indexes, test_indexes = get_data_split(len(data), seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data['target'] = (data['totals'] >= 1) & (data['ups'] * 1.0 / (data['totals']) >= 0.7)\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "recalculate_features = False\n",
    "cache_features = False\n",
    "if recalculate_features:\n",
    "    name_to_feature_dict = extract_features(data, train_indexes, do_not_consider={'vectorized_summary', 'word_embedding'})\n",
    "    if cache_features:\n",
    "        cPickle.dump(name_to_feature_dict, open(filename_without_extension + '_name_to_feature_dict.pkl', 'wb'), protocol=cPickle.HIGHEST_PROTOCOL)\n",
    "else:\n",
    "    name_to_feature_dict = cPickle.load(open(filename_without_extension + '_name_to_feature_dict.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "numerical_feature_names = ['length', 'overall', 'price', 'review_lateness', 'product_review_number', 'review_year']\n",
    "bag_feature_names = ['vectorized_reviews', 'vectorized_product_title', 'vectorized_reviewer_name',\n",
    "                     'vectorized_category']\n",
    "special_feature_names = ['leaf_feature']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Calculate leaf feature\n",
    "numerical_features = get_features_by_names(name_to_feature_dict, numerical_feature_names)\n",
    "leaf_feature = extract_leaf_feature(numerical_features, data['target'],\n",
    "                                    train_indexes, {'n_estimators': 100, 'max_depth': 11})\n",
    "name_to_feature_dict['leaf_feature'] = leaf_feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model and Hyperparameter selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from hyperopt import fmin, tpe, hp, rand\n",
    "def f(params):\n",
    "    start_time = time.time()\n",
    "    for name in clip_set:\n",
    "        if name in params:\n",
    "            params[name] = int(params[name])\n",
    "    print 'using ', params\n",
    "    model = clf.set_params(**params)\n",
    "    model.fit(features[train_indexes], data.loc[train_indexes]['target'])\n",
    "    train_prob_preds = model.predict_proba(features[train_indexes])\n",
    "    training_auc = metrics.average_precision_score(data.loc[train_indexes]['target'], train_prob_preds[:,1])\n",
    "    valid_prob_preds = model.predict_proba(features[valid_indexes])\n",
    "    valid_auc = metrics.average_precision_score(data.loc[valid_indexes]['target'], valid_prob_preds[:,1])\n",
    "    print 'training_auc', training_auc\n",
    "    print 'valid_auc', valid_auc\n",
    "    print 'time %.2f mins'%((time.time() - start_time) / 60)\n",
    "    return -valid_auc\n",
    "\n",
    "model_name = 'MultinomialNB'\n",
    "\n",
    "if model_name == 'XGBClassifier':\n",
    "    clf = XGBClassifier()\n",
    "    space = {'n_estimators':hp.quniform('n_estimators', 100, 400, 5),\n",
    "             'max_depth': hp.quniform('max_depth', 2, 20, 1),\n",
    "             'min_child_weight':hp.uniform('min_child_weight', 0.00001, 20),\n",
    "             'gamma':hp.uniform('gamma', 0.00001, 20)}\n",
    "    clip_set = {'n_estimators', 'max_depth'}\n",
    "    used_feature_names = bag_feature_names + numerical_feature_names\n",
    "elif model_name == 'LogisticRegression':\n",
    "    clf = LogisticRegression()\n",
    "    space = {'C':hp.loguniform('C', -5, 5)}\n",
    "    clip_set = {}\n",
    "    used_feature_names = bag_feature_names\n",
    "elif model_name == 'MultinomialNB':\n",
    "    clf = naive_bayes.MultinomialNB()\n",
    "    space = {'alpha':hp.uniform('alpha', 0, 10)}\n",
    "    clip_set = {}\n",
    "    used_feature_names = bag_feature_names\n",
    "else:\n",
    "    print model_name + \"doesn't exist\"\n",
    "\n",
    "features = get_features_by_names(name_to_feature_dict, used_feature_names)\n",
    "print 'feature shape:', features.shape\n",
    "best = fmin(fn=f,\n",
    "    space=space,\n",
    "    algo=tpe.suggest,\n",
    "    max_evals=40)\n",
    "print best\n",
    "f(best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manually Try specific model and parameters based on the previous cell\n",
    "Trained on training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "used_feature_names = bag_feature_names + numerical_feature_names\n",
    "features = get_features_by_names(name_to_feature_dict, used_feature_names, scale_feature_names=numerical_feature_names)\n",
    "print 'feature shape:', features.shape\n",
    "# model = LogisticRegression(C=0.101)\n",
    "# model = XGBClassifier(n_estimators=300, max_depth=6)\n",
    "# model = sklearn.linear_model.SGDClassifier(loss='log', n_iter=40, alpha=0.00011)\n",
    "# model = naive_bayes.MultinomialNB(alpha=0.154)\n",
    "# model = DummyClassifier()\n",
    "model = XGBClassifier(**{'n_estimators': 200, 'max_depth': 13, 'gamma': 13, 'min_child_weight': 6})\n",
    "\n",
    "train_and_evaluate(model, features, data, train_indexes, valid_indexes, test_indexes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add features one by one to evaluate features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Feature addition test\n",
    "used_feature_names = ['vectorized_reviews', 'vectorized_product_title', 'length', 'overall', 'vectorized_reviewer_name',\n",
    "                       'price', 'vectorized_category', 'review_lateness', 'product_review_number', 'review_year']\n",
    "features = hstack(map(name_to_feature_dict.__getitem__, used_feature_names), format='csr')\n",
    "training_aucs = []\n",
    "valid_aucs = []\n",
    "model = XGBClassifier(**{'n_estimators': 200, 'max_depth': 13, 'gamma': 13, 'min_child_weight': 6})\n",
    "for i in range(0, len(used_feature_names)):\n",
    "    print '------------------------------'\n",
    "    temp_feature_names = used_feature_names[:i + 1]\n",
    "    print 'use', temp_feature_names\n",
    "    features = hstack(map(name_to_feature_dict.__getitem__, temp_feature_names), format='csr')\n",
    "    model.fit(features[train_indexes], data.loc[train_indexes]['target'])\n",
    "\n",
    "    print 'training set'\n",
    "    train_prob_preds = model.predict_proba(features[train_indexes])\n",
    "    evaluate(data.loc[train_indexes]['target'], train_prob_preds[:,1])\n",
    "    training_auc = metrics.average_precision_score(data.loc[train_indexes]['target'], train_prob_preds[:,1])\n",
    "    training_aucs.append(training_auc)\n",
    "\n",
    "    print ''\n",
    "    print 'validation set'\n",
    "    valid_prob_preds = model.predict_proba(features[valid_indexes])\n",
    "    evaluate(data.loc[valid_indexes]['target'], valid_prob_preds[:,1])\n",
    "    \n",
    "    valid_auc = metrics.average_precision_score(data.loc[valid_indexes]['target'], valid_prob_preds[:,1])\n",
    "    valid_aucs.append(valid_auc)\n",
    "\n",
    "print 'training AUC', zip(used_feature_names, map(lambda x:'%.4f'%(x), training_aucs))\n",
    "print 'validation AUC', zip(used_feature_names, map(lambda x:'%.4f'%(x), valid_aucs)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Result\n",
    "Trained on trainging and validation set, test on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dev_indexes = np.concatenate([train_indexes, valid_indexes])\n",
    "final_name_to_feature_dict = extract_features(data, dev_indexes, do_not_consider={'vectorized_summary', 'word_embedding'})\n",
    "used_feature_names = ['vectorized_reviews', 'vectorized_product_title', 'length', 'overall', 'vectorized_reviewer_name',\n",
    "                      'price', 'vectorized_category', 'review_lateness', 'product_review_number', 'review_year']\n",
    "final_features = get_features_by_names(final_name_to_feature_dict, used_feature_names)\n",
    "print 'feature shape:', features.shape\n",
    "\n",
    "final_model = XGBClassifier(**{'n_estimators': 200, 'max_depth': 13, 'gamma': 13, 'min_child_weight': 6})\n",
    "final_model.fit(final_features[dev_indexes], data.loc[dev_indexes]['target'])\n",
    "\n",
    "print ''\n",
    "print 'dev set'\n",
    "dev_prob_preds = final_model.predict_proba(final_features[dev_indexes])\n",
    "evaluate(data.loc[dev_indexes]['target'], dev_prob_preds[:,1])\n",
    "\n",
    "print ''\n",
    "print 'test set'\n",
    "test_prob_preds = final_model.predict_proba(final_features[test_indexes])\n",
    "evaluate(data.loc[test_indexes]['target'], test_prob_preds[:,1], draw_roc=True, draw_precision_recall_curve=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
